{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/collected_data.csv\"\n",
    "original_df = pd.read_csv(path)\n",
    "\n",
    "path = \"data/Japanese_group_template.xlsx\"\n",
    "group_cat = pd.read_excel(path)\n",
    "group_cat = {k: v for k, v in zip(group_cat[\"Group\"], group_cat[\"Category\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>check</th>\n",
       "      <th>model</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>3</td>\n",
       "      <td>439</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>1</td>\n",
       "      <td>1058</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLM-jp</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>3523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "check   model   1     2     3\n",
       "0       Gemma   3   439  3170\n",
       "1        Qwen   1  1058  2553\n",
       "2      LLM-jp  80     9  3523"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"no\", \"model\", \"format\", \"group\", \"check\"] + list(original_df.columns[9:])\n",
    "df = original_df.copy()[cols]\n",
    "df[\"check\"] = df[\"check\"].map(lambda x: int(str(x)[:1]))\n",
    "\n",
    "d = df.groupby([\"model\", \"check\"]).size().unstack().fillna(0).astype(int)\n",
    "dic = {\"Gemma\":1, \"Qwen\":2, \"LLM-jp\":3}\n",
    "d = d.sort_values(\"model\", key=lambda x: x.map(dic)).reset_index()\n",
    "\n",
    "df = df[df[\"check\"] != 1].reset_index(drop=True)\n",
    "for col in df.columns[4:]:\n",
    "    df[col] = df[col].map(lambda x: str(x).replace(\"‚óè\", \"\"))\n",
    "df[\"format\"] = df[\"format\"].map(lambda x: x.replace(\"opinion_pos\",\"positive opinion\").replace(\"opinion_neg\",\"negative opinion\"))\n",
    "df[\"group\"] = df[\"group\"].map(lambda x: group_cat[x])\n",
    "df.rename(columns={\"group\": \"category\"}, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Gemma\", \"Qwen\", \"LLM-jp\"]\n",
    "formats = df['format'].unique()\n",
    "categories = df['category'].unique()\n",
    "def sort_dic(li):\n",
    "    return  {k: v+1 for k, v in zip(li, range(len(li)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_df: toxicity and sentiment\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "row_df = df.copy()\n",
    "row_df = row_df.melt(id_vars=[\"no\"], var_name=\"option\", value_name=\"text\")\n",
    "row_df[\"option\"] = row_df[\"option\"].apply(lambda x: f\"{int(x.split('_')[1]):02d}\")\n",
    "row_df = row_df.sort_values(by=[\"no\", \"option\"]).reset_index(drop=True)\n",
    "print(f\"Number of rows: {len(row_df)}\")\n",
    "\n",
    "row_df['text'] = row_df['text'].map(lambda x: \"\" if str(x) == \"nan\" else x)\n",
    "row_df = row_df[row_df[\"text\"] != \"\"].reset_index(drop=True)\n",
    "print(f\"Number of rows: {len(row_df)}\")\n",
    "\n",
    "row_df[\"ind\"] = row_df[\"no\"].astype(str) + \"_\" + row_df[\"option\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Refusal rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: refusal rate for \"model*format\"\n",
    "\n",
    "x1 = \"model\"\n",
    "x2 = \"format\"\n",
    "v1 = models\n",
    "v2 = formats\n",
    "\n",
    "refusal_df = df.groupby([x1, x2, \"check\"]).size().unstack().fillna(0).astype(int)\n",
    "refusal_df = refusal_df.sort_values(x2, key=lambda x: x.map(sort_dic(v2))).sort_values(x1, key=lambda x: x.map(sort_dic(v1))).reset_index()\n",
    "refusal_df[\"sum\"] = refusal_df[\"2\"] + refusal_df[\"3\"]\n",
    "refusal_df[\"refusal\"] = refusal_df[\"2\"] / refusal_df[\"sum\"]\n",
    "# refusal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JP: https://zenn.dev/taro_tenugui/articles/3d318410dc7a1e\n",
    "# Ofiicial: https://developers.perspectiveapi.com/s/docs-sample-requests?language=en_US\n",
    "\n",
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "client = discovery.build(\n",
    "\"commentanalyzer\",\n",
    "\"v1alpha1\",\n",
    "developerKey=API_KEY,\n",
    "discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "static_discovery=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "row_df[\"result\"] = None\n",
    "\n",
    "i = 0\n",
    "while i < len(row_df):\n",
    "    row = row_df.iloc[i,:]\n",
    "    if row[\"result\"] == \"\":\n",
    "        text = row['text']\n",
    "        print(f\"=== {i}: {text} ======================\")\n",
    "\n",
    "        analyze_request = {\n",
    "            'comment': {'text': text},\n",
    "            'languages': ['ja'],  # Japanese\n",
    "            'requestedAttributes': {'TOXICITY': {}}\n",
    "        }\n",
    "\n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "        print(response)\n",
    "        row_df.at[i, \"result\"] = response\n",
    "        time.sleep(1)  # wait 1min.\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i, row in row_df.iterrows():\n",
    "    text = row[\"result\"]\n",
    "    try:\n",
    "        text = str(text).replace(\"'\", '\"')\n",
    "        dic = json.loads(text)\n",
    "        values.append(dic['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "    except:\n",
    "        print(i, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_df = row_df.copy()\n",
    "toxic_df[\"toxicity\"] = values\n",
    "toxic_df = toxic_df[[\"no\",\"toxicity\"]]\n",
    "def f(x):\n",
    "    return \",\".join([str(round(i, 4)) for i in x])\n",
    "toxic_df = toxic_df.groupby(\"no\").agg({\"toxicity\": f}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/koheiduck/bert-japanese-finetuned-sentiment\"\n",
    "headers = {\"Authorization\": \"Bearer hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\t# time.sleep(0.1)\n",
    "\treturn response.json()\n",
    "\n",
    "def apply_senti(text):\n",
    "\toutput = query({ \"inputs\": text})\n",
    "\treturn [round(x['score'], 4) for x in output[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = len(all_dic)\n",
    "print(f\"Start from {i}\")\n",
    "while i < len(row_df):\n",
    "    try:\n",
    "        scores = apply_senti(row_df['text'][i])\n",
    "        all_dic[i] = scores\n",
    "        i += 1\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        break\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{i} done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_df['pos'] = [x[0] for x in all_scores]\n",
    "row_df['neu'] = [x[1] for x in all_scores]\n",
    "row_df['neg'] = [x[2] for x in all_scores]\n",
    "\n",
    "def pos(x):\n",
    "    return sum([1 for i in x if i == \"POSITIVE\"])\n",
    "def neg(x):\n",
    "    return sum([1 for i in x if i == \"NEGATIVE\"])\n",
    "def neu(x):\n",
    "    return sum([1 for i in x if i == \"NEUTRAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"no\"] + row_df.columns[6:].tolist()\n",
    "senti_df = row_df[cols].copy().groupby(\"no\").agg({\"label\": [pos, neg, neu]})\n",
    "senti_df['total'] = senti_df['label'].sum(axis=1)\n",
    "senti_df.columns = [\"pos\", \"neg\", \"neu\", \"total\"]\n",
    "senti_df['pn_score'] = round((senti_df['pos'] - senti_df['neg']) / senti_df['total'], 3)\n",
    "\n",
    "senti_df = pd.merge(senti_df, df, on=\"no\", how=\"left\")\n",
    "senti_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
